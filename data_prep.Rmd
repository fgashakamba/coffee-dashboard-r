---
  title: "Coffee Data Preparation"
output: html_document
---
  
```{r data_prep, include=FALSE}

# --- 1. LOAD PACKAGES ---
# All packages needed for data processing
if(!require("pacman")) install.packages("pacman")
pacman::p_load(magrittr, dplyr, readr, stringr, tidyr, lubridate,
               sf, googlesheets4, openssl, janitor, classInt)

# --- 2. FETCH AND PROCESS DATA---
# Authenticate with Google Sheets
b64 <- Sys.getenv("GSHEET_SERVICE_JSON_BASE64")
decoded_raw <- base64_decode(b64)
tmp <- tempfile(fileext = ".json")
writeBin(decoded_raw, tmp)
gs4_auth(path = tmp)

# Load the input datasets from Google Sheets
url <- "https://docs.google.com/spreadsheets/d/1S2tvQ2S2GBQffGXAxLTExDu0i24jHxj7NwG-gWPahD4"
data_farms_raw <- range_read(url, sheet = "Coffee_farms", range = "A1:AE")
data_cws_raw <- range_read(url, sheet = "Coffee Washing Stations", range = "A1:Z")
data_coops_raw <- range_read(url, sheet = "Cooperatives", range = "A1:R")
ranges <- c("A:A", "C:C", "D:D", "E:E", "H:H", "I:I", "J:J", "L:L", "S:S", "W:W", "X:X", "Z:Z")
range_list <- lapply(ranges, function(r) {
  range_read(url, sheet = "Coffee farmers", range = r)
})
data_farmers <- do.call(cbind, range_list)

# Process all your data exactly as before
data_coops <- data_coops_raw %>% 
  st_as_sf(coords = c("longitude", "latitude"), sf_column_name = "geom", crs = 4326, remove = T, na.fail = F) %>%
  filter(!st_is_empty(geom)) %>% st_transform(crs = 32736)

data_cws <- data_cws_raw %>% 
  st_as_sf(coords = c("longitude", "latitude"), sf_column_name = "geom", crs = 4326, remove = T, na.fail = F) %>%
  filter(!st_is_empty(geom)) %>% st_transform(crs = 32736)

data_farms <- data_farms_raw %>% 
  st_as_sf(coords = c("longitude", "latitude"), sf_column_name = "geom", crs = 4326, remove = T, na.fail = F) %>%
  filter(!st_is_empty(geom)) %>% st_transform(crs = 32736)

data_farms_stats <- data_farms %>% st_drop_geometry() %>% group_by(national_id, age_range_coffee_trees) %>%
  summarise(area = sum(area_ares, na.rm = T),
            nbr_coffee_trees = sum(as.integer(nbr_coffee_trees), na.rm = T),
            .groups = "drop")

data_farmers %<>% mutate(cws_id = str_replace_all(str_squish(str_to_lower(farmer_cws)), " ", "_"))
data_farmers %<>% mutate(cooperative_id = str_replace_all(str_squish(str_to_lower(cooperative)), " ", "_"))
data_farmers_full <- data_farmers %>% select(national_id, district, training_topics, cooperative_id, cws_id) %>%
  left_join(data_farms_stats, by = "national_id")

# Load and process geospatial data
country <- st_read(paste(getwd(),"data_wgs84", "RW_country.gpkg", sep = "/"), layer = "country") %>% 
  st_zm(drop = T, what = "ZM") %>%  st_make_valid(.) %>% st_transform(crs = 32736)
lakes <- st_read(paste(getwd(),"data_wgs84", "RW_lakes.gpkg", sep = "/"), layer = "lakes") %>% 
  st_zm(drop = T, what = "ZM") %>%  st_make_valid(.) %>% st_transform(crs = 32736)
np <- st_read(paste(getwd(),"data_wgs84", "RW_national_parks.gpkg", sep = "/"), layer = "np") %>% 
  st_zm(drop = T, what = "ZM") %>%  st_make_valid(.) %>% st_transform(crs = 32736)
districts <- st_read(paste(getwd(),"data_wgs84", "RW_districts.gpkg", sep = "/"), layer = "districts") %>% 
  st_zm(drop = T, what = "ZM") %>%  st_make_valid(.) %>% st_transform(crs = 32736) %>%
  mutate(district = str_to_lower(district))

# --- 3. SAVE THE PROCESSED DATA ---
# Bundle all the necessary final objects into a list
app_data <- list(
  data_farmers_full = data_farmers_full,
  data_coops = data_coops,
  data_cws = data_cws,
  data_farms = data_farms,
  country = country,
  lakes = lakes,
  np = np,
  districts = districts
)

# Save the single list object to an .rds file
# This file will be read by your Shiny app
saveRDS(app_data, "coffee_dashboard_data.rds")
```